# Default security context for airflow
securityContext:
  #  runAsUser: 50000
  fsGroup: 65534
#  runAsGroup: 0

# Default airflow tag to deploy
defaultAirflowTag: "2.3.3"

# Airflow version (Used to make some decisions based on Airflow Version being deployed)
airflowVersion: "2.3.3"

executor: "KubernetesExecutor"

# main Airflow configmap
airflowConfigAnnotations: {}

# Select certain nodes for airflow pods.
nodeSelector:
  NodeGroupType: core

#----------------------------------------------------
# Ingress configuration
#----------------------------------------------------
ingress:
  web:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/group.name: "dev"
      alb.ingress.kubernetes.io/target-type : "instance"
      #      alb.ingress.kubernetes.io/certificate-arn: "arn:aws:acm:....................."
      alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
      alb.ingress.kubernetes.io/actions.ssl-redirect: '{"Type": "redirect", "RedirectConfig": { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}}'
    path: "/dev"
    # The pathType for the above path (used only with Kubernetes v1.19 and above)
    pathType: "Prefix"
    # The hostnames or hosts configuration for the web Ingress
    hosts:
      - name: ""
        # configs for web Ingress TLS
        tls:
          # Enable TLS termination for the web Ingress
          enabled: false
          # the name of a pre-created Secret containing a TLS private key and certificate
          secretName: ""
    # The Ingress Class for the web Ingress (used only with Kubernetes v1.19 and above)
    ingressClassName: "alb"

#----------------------------------------------------
# Airflow database & redis config
#----------------------------------------------------
data:
  #  kubectl create secret generic mydatabase --from-literal=connection=postgresql://user:pass@host:5432/db
  #  metadataSecretName: ~

  # Otherwise pass connection values in
  metadataConnection:
    user: airflow
    pass: AirflowEKS # Get this from Secrets manager
    protocol: postgresql
    host: emr-eks-fsx-lustre.cru3ngo5qdjr.eu-west-1.rds.amazonaws.com
    port: 5432
    db: airflow
    sslmode: disable
#----------------------------------------------------
# Airflow Worker Config
#----------------------------------------------------
#workers:
#  replicas: 2
#  serviceAccount:
#    create: false # change this to false provide the name created by Terraform
#    name: airflow-worker
#    annotations:
#      eks.amazonaws.com/role-arn: arn:aws:iam::327949925549:role/eksctl-emr-eks-fsx-lustre-addon-iamserviceac-Role1-PCTHU9ZJKHRW
#  persistence:
#    enabled: false
#  resources:
#    limits:
#     cpu: 200m
#     memory: 256Mi
#    requests:
#     cpu: 200m
#     memory: 256Mi

#----------------------------------------------------
# Airflow scheduler settings
#----------------------------------------------------
scheduler:
  replicas: 2
  serviceAccount:
    create: false
    name: airflow
    annotations:
      eks.amazonaws.com/role-arn: arn:aws:iam::327949925549:role/eksctl-emr-eks-fsx-lustre-addon-iamserviceac-Role1-PCTHU9ZJKHRW
  resources:
    limits:
      cpu: 200m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 512Mi

#----------------------------------------------------
# Airflow database migration job settings
#----------------------------------------------------
migrateDatabaseJob:
  enabled: true

#----------------------------------------------------
# Airflow webserver settings
#----------------------------------------------------
webserver:
  # Number of webservers
  replicas: 2
  serviceAccount:
    create: true
    name: airflow
    annotations:
      eks.amazonaws.com/role-arn: arn:aws:iam::327949925549:role/eksctl-emr-eks-fsx-lustre-addon-iamserviceac-Role1-PCTHU9ZJKHRW
  resources:
    limits:
      cpu: 200m
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 1Gi
  allowPodLogReading: true
#  livenessProbe:
#    initialDelaySeconds: 60
#    timeoutSeconds: 30
#    failureThreshold: 20
#    periodSeconds: 5
#
#  readinessProbe:
#    initialDelaySeconds: 60
#    timeoutSeconds: 30
#    failureThreshold: 20
#    periodSeconds: 5

#----------------------------------------------------
# Airflow Triggerer Config
#----------------------------------------------------
triggerer:
  enabled: true

#----------------------------------------------------
# Airflow Dag Processor Config
#----------------------------------------------------
dagProcessor:
  enabled: false

#----------------------------------------------------
# StatsD settings
#----------------------------------------------------
statsd:
  enabled: true
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
#----------------------------------------------------
# PgBouncer settings
#----------------------------------------------------
pgbouncer:
  enabled: true
  auth_type: scram-sha-256

#----------------------------------------------------
# All ports used by chart
#----------------------------------------------------
ports:
  flowerUI: 5555
  airflowUI: 8080
  workerLogs: 8793
  redisDB: 6379
  statsdIngest: 9125
  statsdScrape: 9102
  pgbouncer: 6543
  pgbouncerScrape: 9127

#----------------------------------------------------
# Disable local postgresql for external RDS implementation
#----------------------------------------------------
postgresql:
  enabled: false

config:
  core:
    dags_folder: '{{ include "airflow_dags" . }}'
    load_examples: 'False'
    executor: '{{ .Values.executor }}'
    colored_console_log: 'True'
    remote_logging: 'True'
  logging:
    remote_logging: 'True'
    logging_level: 'INFO'
    colored_console_log: 'True'
    remote_base_log_folder: 's3://dev-aws-raw-zone/airflow-logs'
    remote_log_conn_id: 'aws_s3_conn'
    delete_worker_pods: 'False'
    encrypt_s3_logs: 'True'
  metrics:
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
    statsd_host: '{{ printf "%s-statsd" .Release.Name }}'
  webserver:
    enable_proxy_fix: 'True'
    rbac: 'True'
  scheduler:
    standalone_dag_processor: '{{ ternary "True" "False" .Values.dagProcessor.enabled }}'
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
    statsd_host: '{{ printf "%s-statsd" .Release.Name }}'
    run_duration: 41460
  kubernetes:
    namespace: '{{ .Release.Namespace }}'
    airflow_configmap: '{{ include "airflow_config" . }}'
    airflow_local_settings_configmap: '{{ include "airflow_config" . }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}'
    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}'
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'

#----------------------------------------------------
# Git sync
# Move this to example
#----------------------------------------------------
dags:
  persistence:
    enabled: false
  gitSync:
    enabled: true
    repo: git@github.com:Hyper-Mesh/airflow-dags.git
    branch: main
    rev: HEAD
    depth: 1
    maxFailures: 0
    subPath: "dags"
    sshKeySecret: airflow-git-ssh-secret

    knownHosts: |
      github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==

    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 128Mi

