#----------------------------------------------------
# Default security context for airflow
#----------------------------------------------------
securityContext:
  fsGroup: 65534

# Default airflow tag to deploy
defaultAirflowTag: "2.3.3"

# Airflow version (Used to make some decisions based on Airflow Version being deployed)
airflowVersion: "2.3.3"

executor: "KubernetesExecutor"
#----------------------------------------------------
# Ingress configuration
#----------------------------------------------------
ingress:
  web:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/group.name: "dev"
      alb.ingress.kubernetes.io/target-type : "instance"
      #      alb.ingress.kubernetes.io/certificate-arn: "arn:aws:acm:....................."
      alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
      alb.ingress.kubernetes.io/actions.ssl-redirect: '{"Type": "redirect", "RedirectConfig": { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}}'
    path: "/dev"
    # The pathType for the above path (used only with Kubernetes v1.19 and above)
    pathType: "Prefix"
    # The hostnames or hosts configuration for the web Ingress
    hosts:
      - name: ""
        # configs for web Ingress TLS
        tls:
          # Enable TLS termination for the web Ingress
          enabled: false
          # the name of a pre-created Secret containing a TLS private key and certificate
          secretName: ""
    # The Ingress Class for the web Ingress (used only with Kubernetes v1.19 and above)
    ingressClassName: "alb"

#----------------------------------------------------
# Airflow database
#----------------------------------------------------
data:
  metadataConnection:
    user: airflow
    pass: ""
    protocol: postgresql
    host: ${airflow_db_host}
    port: 5432
    db: airfow
    sslmode: disable

#----------------------------------------------------
# Airflow Worker Config
workers:
  replicas: 2
  serviceAccount:
    create: false
    name: airflow-webserver-sa

  persistence:
    enabled: false
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 200m
      memory: 256Mi
#----------------------------------------------------
# Airflow scheduler settings
#----------------------------------------------------
scheduler:
  replicas: 2
  serviceAccount:
    create: false
    name: airflow-webserver-sa
#    annotations:
#      eks.amazonaws.com/role-arn: arn:aws:iam::327949925549:role/eksctl-emr-eks-fsx-lustre-addon-iamserviceac-Role1-PCTHU9ZJKHRW
  resources:
    limits:
      cpu: 200m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 512Mi

#----------------------------------------------------
# Airflow database migration job settings
#----------------------------------------------------
migrateDatabaseJob:
  enabled: true

#----------------------------------------------------
# Airflow webserver settings
#----------------------------------------------------
#webserverSecretKeySecretName: ${webserver_secret_name}

webserver:
  # Number of webservers
  replicas: 2
  serviceAccount:
    create: false
    name: airflow-webserver-sa

  allowPodLogReading: true
  livenessProbe:
    initialDelaySeconds: 15
    timeoutSeconds: 30
    failureThreshold: 20
    periodSeconds: 5

  readinessProbe:
    initialDelaySeconds: 15
    timeoutSeconds: 30
    failureThreshold: 20
    periodSeconds: 5

  resources:
    limits:
      cpu: 200m
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 1Gi

  # Create initial user.
  defaultUser:
    enabled: true
    role: Admin
    username: admin
    email: admin@example.com
    firstName: admin
    lastName: user
    password: admin

#  service:
#    type: ClusterIP
#    ## service annotations
#    annotations: { }
#    ports:
#      - name: airflow-ui
#        port: "{{ .Values.ports.airflowUI }}"
#    loadBalancerIP: ~
#    ## Limit load balancer source ips to list of CIDRs
#    # loadBalancerSourceRanges:
#    #   - "10.123.0.0/16"
#    loadBalancerSourceRanges: [ ]
#----------------------------------------------------
# Airflow Triggerer Config
#----------------------------------------------------
triggerer:
  enabled: true

#----------------------------------------------------
# Airflow Dag Processor Config
#----------------------------------------------------
dagProcessor:
  enabled: false

#----------------------------------------------------
# StatsD settings
#----------------------------------------------------
statsd:
  enabled: true
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
#----------------------------------------------------
# PgBouncer settings
#----------------------------------------------------
pgbouncer:
  enabled: true
  auth_type: scram-sha-256

#----------------------------------------------------
# All ports used by chart
#----------------------------------------------------
ports:
  flowerUI: 5555
  airflowUI: 8080
  workerLogs: 8793
  redisDB: 6379
  statsdIngest: 9125
  statsdScrape: 9102
  pgbouncer: 6543
  pgbouncerScrape: 9127

#----------------------------------------------------
# Disable local postgresql for external RDS implementation
#----------------------------------------------------
postgresql:
  enabled: false

config:
  core:
    dags_folder: '{{ include "airflow_dags" . }}'
    load_examples: 'False'
    executor: '{{ .Values.executor }}'
    colored_console_log: 'True'
    remote_logging: 'True'
  logging:
    remote_logging: 'True'
    logging_level: 'INFO'
    colored_console_log: 'True'
    remote_base_log_folder: "s3://${s3_bucket_name}/airflow-logs"
    remote_log_conn_id: 'aws_s3_conn' # Create the connection using WebUI
    delete_worker_pods: 'False'
    encrypt_s3_logs: 'True'
  metrics:
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
    statsd_host: '{{ printf "%s-statsd" .Release.Name }}'
  webserver:
    enable_proxy_fix: 'True'
    rbac: 'True'
  scheduler:
    standalone_dag_processor: '{{ ternary "True" "False" .Values.dagProcessor.enabled }}'
    statsd_on: '{{ ternary "True" "False" .Values.statsd.enabled }}'
    statsd_port: 9125
    statsd_prefix: airflow
    statsd_host: '{{ printf "%s-statsd" .Release.Name }}'
    run_duration: 41460
  kubernetes:
    namespace: '{{ .Release.Namespace }}'
    airflow_configmap: '{{ include "airflow_config" . }}'
    airflow_local_settings_configmap: '{{ include "airflow_config" . }}'
    pod_template_file: '{{ include "airflow_pod_template_file" . }}/pod_template_file.yaml'
    worker_container_repository: '{{ .Values.images.airflow.repository | default .Values.defaultAirflowRepository }}'
    worker_container_tag: '{{ .Values.images.airflow.tag | default .Values.defaultAirflowTag }}'
    multi_namespace_mode: '{{ ternary "True" "False" .Values.multiNamespaceMode }}'

#----------------------------------------------------
# Git sync
# Mounting DAGs using Git-Sync sidecar with EFS Persistence enabled
# ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
# base64 <my-private-ssh-key> -w 0 > temp.txt
#
#----------------------------------------------------
dags:
  persistence:
    enabled: false
    size: 100Gi
    storageClassName: efs-sc
    accessMode: ReadWriteMany

  gitSync:
    enabled: true
    repo: git@github.com:Hyper-Mesh/airflow-dags.git
    branch: main
    rev: HEAD
    depth: 1
    maxFailures: 0
    subPath: "dags"
    sshKeySecret: ${airflow_git_ssh_secret}
    knownHosts: |
      github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==

    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 128Mi

